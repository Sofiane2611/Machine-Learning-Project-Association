{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e2u6taMiTat"
      },
      "source": [
        "Machine Learning Project : Association rules mining using Apriori algorithm.\r\n",
        "1- Introduction\r\n",
        "Association Rules is one of the very important concepts of machine learning being used in market basket analysis. In a store, all vegetables are placed in the same aisle, all dairy items are placed together and cosmetics form another set of such groups. Investing time and resources on deliberate product placements like this not only reduces a customer’s shopping time, but also reminds the customer of what relevant items (s)he might be interested in buying, thus helping stores cross-sell in the process. Association rules help uncover all such relationships between items from huge databases. One important thing to note is- Rules do not extract an individual’s preference, rather find relationships between set of elements of every distinct transaction.\r\n",
        "\r\n",
        "2- Dataset\r\n",
        "We used the grocery dataset, which can be found on kaggle. The dataset contains 9835 transactions by customers shopping for groceries. The data contains 169 unique items.\r\n",
        "\r\n",
        "3- Approach\r\n",
        "This kernel has 7 main sections :\r\n",
        "\r\n",
        "Importing libraries\r\n",
        "Reading the Datasert\r\n",
        "Exploratory Data Analysis ;\r\n",
        "Data Vizualisation ;\r\n",
        "Data Preprocessing ;\r\n",
        "Association rules ;\r\n",
        "Conclusion.\r\n",
        "1. Importing libraries :\r\n",
        "For basic operation, we need to use 2 libraries : Numpy and Pandas For vizualisation we need to use : matplotlib, seaborn, wordcloud ans squarify For preprocessing we need to use : TransactionEncoder For market basket analysis we need to use Mlxtend\r\n",
        "\r\n",
        "2. Reading the dataset :\r\n",
        "To read our datasetWe, we will need to use the pd.read_csv method for\r\n",
        "\r\n",
        "3. Exploratory Data Analysis :\r\n",
        "To understand our dataset, we need to know more about our dataset, so we going to kno about the shape of our dataset, information about our dataset including the index dtype and columns, non-null values and memory usage, the number of missing values in the dataset, the List unique values.\r\n",
        "\r\n",
        "4. Datavizuamisation :\r\n",
        "For vizualisation, we use 4 method :\r\n",
        "\r\n",
        "Data vizualisation by Wordcloud ;\r\n",
        "Data vizualisation by Bar graph ;\r\n",
        "Data vizualisation by Tree Map ;\r\n",
        "Data vizualisation by Networkx.\r\n",
        "5. Data Preprocessing\r\n",
        "To know all the different products in the transactions, we must assign to each of them a list that contains a boolean\r\n",
        "array where each index represents the corresponding product, whether it is purchased in the transaction or not. But first our dataset needs a preprocessing by converting into required format of TransactionEncoder. So we need to :\r\n",
        "\r\n",
        "making each customers shopping items an identical list\r\n",
        "converting it into an numpy array\r\n",
        "checking the shape of the array\r\n",
        "6. Association Rules\r\n",
        "To solve this case study, we need to use the Apriori Algorithm, and we must explain the approach of the method.\r\n",
        "\r\n",
        "Association rule is unsupervised learning where algorithm tries to learn without a teacher as data are not labelled. Association rule is descriptive not the predictive method, generally used to discover interesting relationship hidden in large datasets. The relationship are usually represented in form of rules or frequent itemsets.\r\n",
        "\r\n",
        "Apriori Concept\r\n",
        "Apriori is one of the algorithms that we can use for market basket analysis.\r\n",
        "\r\n",
        "Apriori is based on 3 metrics:\r\n",
        "a.Support\r\n",
        "\r\n",
        "b.Confidence\r\n",
        "\r\n",
        "c.Lift\r\n",
        "\r\n",
        "a. Support :\r\n",
        "Quantify how many times an item or an itemset appear in a set of transactions. In other words, support quantifies the frequency of an itemset.\r\n",
        "\r\n",
        "b. Confidence :\r\n",
        "After buying an item X what’s the probability of buying item Y.\r\n",
        "\r\n",
        "c. Lift :\r\n",
        "What’s the probability to buy items X and Y together rather than just buying item X."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mz7vrj_iTNT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdsSZ9dHiB5Z"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "plt.style.use('fivethirtyeight')\r\n",
        "from wordcloud import WordCloud\r\n",
        "import squarify\r\n",
        "\r\n",
        "from mlxtend.preprocessing import TransactionEncoder\r\n",
        "from mlxtend.frequent_patterns import apriori\r\n",
        "from mlxtend.frequent_patterns import association_rules"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZVib7E4iZpe"
      },
      "source": [
        "data = pd.read_csv('groceries - groceries.csv')\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmarpuzTibLn"
      },
      "source": [
        "data.shape\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixOx5Qw6icuM"
      },
      "source": [
        "data.info()\r\n",
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPFfgrYBie9Q"
      },
      "source": [
        "data.sample(10)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XcD5T5nigpu"
      },
      "source": [
        "data_It1 = data['Item 1'].unique()\r\n",
        "data_It2 = data['Item 2'].unique()\r\n",
        "data_It3 = data['Item 3'].unique()\r\n",
        "\r\n",
        "print('Unique Product in 1st Item is :', data_It1)\r\n",
        "print('')\r\n",
        "print('Unique Product in 2nd Item is :', data_It2)\r\n",
        "print('')\r\n",
        "print('Unique Product in 3rd Item is :', data_It3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2tKxbxCiiiZ"
      },
      "source": [
        "y = data['Item 1'].value_counts().head(100).to_frame()\r\n",
        "y.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v0PMm65ikjw"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (40, 40)\r\n",
        "\r\n",
        "# 1st Item\r\n",
        "\r\n",
        "plt.subplot2grid ((2,3),(0,0))\r\n",
        "\r\n",
        "wordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 50).generate(str(data['Item 1']))\r\n",
        "plt.imshow(wordcloud)\r\n",
        "plt.axis('off')\r\n",
        "plt.title('Most Popular_1st Items',fontsize = 20)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FayRFF0WimyY"
      },
      "source": [
        "\r\n",
        "# looking at the frequency of most popular items\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (30, 15)\r\n",
        "color = plt.cm.copper(np.linspace(0, 1, 40))\r\n",
        "data['Item 1'].value_counts().head(20).plot.bar(color = color)\r\n",
        "plt.title('frequency of most popular items', fontsize = 20)\r\n",
        "plt.xticks(rotation = 90 )\r\n",
        "plt.grid()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB5HBZZnipaa"
      },
      "source": [
        "# plotting a tree map\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\r\n",
        "color = plt.cm.cool(np.linspace(0, 1, 50))\r\n",
        "squarify.plot(sizes = y.values, label = y.index, alpha=.8, color = color)\r\n",
        "plt.title('Tree Map for Popular Items')\r\n",
        "plt.axis('off')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfSznxnsitEs"
      },
      "source": [
        "data['food'] = 'Food'\r\n",
        "food = data.truncate(before = -1, after = 15)\r\n",
        "\r\n",
        "\r\n",
        "import networkx as nx\r\n",
        "\r\n",
        "food = nx.from_pandas_edgelist(food, source = 'food', target = 'Item 1', edge_attr = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDq1B5s-ivRE"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\r\n",
        "pos = nx.spring_layout(food)\r\n",
        "color = plt.cm.Wistia(np.linspace(0, 15, 1))\r\n",
        "nx.draw_networkx_nodes(food, pos, node_size = 15000, node_color = color)\r\n",
        "nx.draw_networkx_edges(food, pos, width = 3, alpha = 0.6, edge_color = 'black')\r\n",
        "nx.draw_networkx_labels(food, pos, font_size = 20, font_family = 'sans-serif')\r\n",
        "plt.axis('off')\r\n",
        "plt.grid()\r\n",
        "plt.title('Top 15 First Choices', fontsize = 40)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLWt7jquixGT"
      },
      "source": [
        "data['secondchoice'] = 'Second Choice'\r\n",
        "secondchoice = data.truncate(before = -1, after = 15)\r\n",
        "secondchoice = nx.from_pandas_edgelist(secondchoice, source = 'food', target = 'Item 2', edge_attr = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouM1uU2tizqS"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\r\n",
        "pos = nx.spring_layout(secondchoice)\r\n",
        "color = plt.cm.Blues(np.linspace(0, 15, 1))\r\n",
        "nx.draw_networkx_nodes(secondchoice, pos, node_size = 15000, node_color = color)\r\n",
        "nx.draw_networkx_edges(secondchoice, pos, width = 3, alpha = 0.6, edge_color = 'brown')\r\n",
        "nx.draw_networkx_labels(secondchoice, pos, font_size = 20, font_family = 'sans-serif')\r\n",
        "plt.axis('off')\r\n",
        "plt.grid()\r\n",
        "plt.title('Top 15 Second Choices', fontsize = 40)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufNLvmlci1Jp"
      },
      "source": [
        "data['thirdchoice'] = 'Third Choice'\r\n",
        "secondchoice = data.truncate(before = -1, after = 15)\r\n",
        "secondchoice = nx.from_pandas_edgelist(secondchoice, source = 'food', target = 'Item 3', edge_attr = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6YCPBXoi3ny"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\r\n",
        "pos = nx.spring_layout(secondchoice)\r\n",
        "color = plt.cm.Reds(np.linspace(0, 15, 1))\r\n",
        "nx.draw_networkx_nodes(secondchoice, pos, node_size = 15000, node_color = color)\r\n",
        "nx.draw_networkx_edges(secondchoice, pos, width = 3, alpha = 0.6, edge_color = 'pink')\r\n",
        "nx.draw_networkx_labels(secondchoice, pos, font_size = 20, font_family = 'sans-serif')\r\n",
        "plt.axis('off')\r\n",
        "plt.grid()\r\n",
        "plt.title('Top 15 Third Choices', fontsize = 40)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHrcSzki5n6"
      },
      "source": [
        "# making each customers shopping items an identical list\r\n",
        "trans = []\r\n",
        "for i in range(0, 9835):\r\n",
        "    trans.append([str(data.values[i,j]) for j in range(0, 33)])\r\n",
        "\r\n",
        "# converting it into an numpy array\r\n",
        "trans = np.array(trans)\r\n",
        "\r\n",
        "# checking the shape of the array\r\n",
        "print(trans.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NckTPIYi7iL"
      },
      "source": [
        "te = TransactionEncoder()\r\n",
        "data = te.fit_transform(trans)\r\n",
        "data = pd.DataFrame(data, columns = te.columns_)\r\n",
        "\r\n",
        "# getting the shape of the data\r\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J48xQaGLi9KA"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "#I'm going to use just 100 Items for my analysis\r\n",
        "\r\n",
        "data = data.loc[:, ['sausage', 'whole milk', 'frankfurter', 'tropical fruit',\r\n",
        "       'other vegetables', 'citrus fruit', 'pork', 'rolls/buns', 'chicken',\r\n",
        "       'canned beer', 'beef', 'soda', 'root vegetables', 'pip fruit', 'yogurt',\r\n",
        "       'ham', 'bottled beer', 'meat', 'bottled water', 'hamburger meat',\r\n",
        "       'pastry', 'berries', 'curd', 'ice cream', 'beverages', 'coffee',\r\n",
        "       'whipped/sour cream', 'butter', 'dessert', 'onions', 'UHT-milk',\r\n",
        "       'grapes', 'brown bread', 'newspapers', 'domestic eggs', 'frozen meals',\r\n",
        "       'finished products', 'misc. beverages', 'turkey', 'shopping bags',\r\n",
        "       'chocolate', 'butter milk', 'salty snack', 'fruit/vegetable juice',\r\n",
        "       'liver loaf', 'frozen vegetables', 'cream cheese',\r\n",
        "       'specialty chocolate', 'packaged fruit/vegetables', 'waffles', 'herbs',\r\n",
        "       'oil', 'photo/film', 'white bread', 'chewing gum', 'margarine',\r\n",
        "       'white wine', 'condensed milk', 'pet care', 'specialty bar', 'cat food',\r\n",
        "       'sugar', 'napkins', 'fish', 'hard cheese', 'long life bakery product',\r\n",
        "       'semi-finished bread', 'processed cheese', 'frozen fish',\r\n",
        "       'hygiene articles', 'nuts/prunes', 'liquor', 'detergent',\r\n",
        "       'sliced cheese', 'candy', 'spread cheese', 'zwieback', 'red/blush wine',\r\n",
        "       'pasta', 'frozen dessert', 'potted plants', 'sparkling wine',\r\n",
        "       'organic sausage', 'dishes', 'seasonal products', 'dog food',\r\n",
        "       'baking powder', 'frozen potato products', 'soft cheese', 'curd cheese',\r\n",
        "       'salt', 'sweet spreads', 'mayonnaise', 'canned vegetables',\r\n",
        "       'specialty cheese', 'chocolate marshmallow', 'flower soil/fertilizer',\r\n",
        "       'cookware', 'dish cleaner', 'instant coffee']]\r\n",
        "\r\n",
        "# checking the shape\r\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IkGWw-Ri_NC"
      },
      "source": [
        "# let's check the columns\r\n",
        "\r\n",
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUAmBSLHjA2J"
      },
      "source": [
        "# getting the head of the data\r\n",
        "\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}